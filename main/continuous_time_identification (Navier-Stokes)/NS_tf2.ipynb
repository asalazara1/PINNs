{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: tensorflow.compat.v1\n",
      "Other supported backends: tensorflow, pytorch, jax, paddle.\n",
      "paddle supports more examples now and is recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No backend selected.\n",
      "Finding available backend...\n",
      "Found tensorflow.compat.v1\n",
      "Setting the default backend to \"tensorflow.compat.v1\". You can change it in the ~/.deepxde/config.json file or export the DDE_BACKEND environment variable. Valid options are: tensorflow.compat.v1, tensorflow, pytorch, jax, paddle (all lowercase)\n",
      "WARNING:tensorflow:From C:\\Users\\Usuario\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From C:\\Users\\Usuario\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\deepxde\\nn\\initializers.py:118: The name tf.keras.initializers.he_normal is deprecated. Please use tf.compat.v1.keras.initializers.he_normal instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import deepxde as dde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual(u,v,u_t,v_t,u_x,u_xx,u_y,u_yy,v_x,v_xx,v_y,v_yy,p_x,p_y,l1, l2):\n",
    "    \n",
    "    f_u = u_t + l1*(u*u_x + v*u_y) + p_x - l2* (u_xx + u_yy)\n",
    "    f_v = v_t + l1*(u*v_x + v*v_y) + p_y - l2* (v_xx + v_yy)\n",
    "\n",
    "    return f_u, f_v\n",
    "\n",
    "class PhysicsInformedNN:\n",
    "    def __init__(self, lb, ub, layers, u0, v0, x0, X):\n",
    "\n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "                \n",
    "        self.layers = layers\n",
    "\n",
    "        self.u0 = u0\n",
    "        self.v0 = v0\n",
    "        self.x0 = x0\n",
    "        self.X = X\n",
    "\n",
    "        self.model = self.initialize_NN(self,layers)\n",
    "\n",
    "    def initialize_NN(self,layers):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.Input(layers[0]))\n",
    "        scaling_layer = tf.keras.layers.Lambda(\n",
    "            lambda x: 2.0*(x-self.lb)/(self.ub-self.lb)-1.0)\n",
    "        model.add(scaling_layer)\n",
    "        num_layers = len(layers)\n",
    "        for i in range(1,num_layers-2):\n",
    "            model.add(tf.keras.layers.Dense(layers[i],\n",
    "                                            activation=tf.keras.activations.get('tanh'),\n",
    "                                            kernel_initializer='glorot_normal'))\n",
    "        model.add(tf.keras.layers.Dense(layers[-1]))\n",
    "\n",
    "        return model\n",
    "    \n",
    "\n",
    "    def loss(self, X, X0, u0, v0):\n",
    "        psi_and_p = self.model(X0)\n",
    "        u_pred =  psi_and_p[:,0:1]\n",
    "        v_pred =  psi_and_p[:,1:2]\n",
    "        p_pred = psi_and_p[:,2:3]\n",
    "\n",
    "        loss = tf.reduce_mean(tf.square(u0-u_pred))\n",
    "        loss += tf.reduce_mean(tf.square(v0-v_pred)) #Revisar\n",
    "\n",
    "        r1,r2 = self.get_residual(self,X)\n",
    "\n",
    "        phi_ru = tf.reduce_mean(tf.square(r1))\n",
    "        phi_rv = tf.reduce_mean(tf.square(r2))\n",
    "\n",
    "        loss += phi_ru \n",
    "        loss += phi_rv\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def get_residual(self,X):\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            x = X[:,0:1]\n",
    "            y = X[:,1:2]\n",
    "            t = X[:,2:3]\n",
    "\n",
    "            tape.watch(x)\n",
    "            tape.watch(y)\n",
    "            tape.watch(t)\n",
    "\n",
    "            psi_and_p = self.model(tf.stack([x[:,0],y[:,0],t[:,0]], axis=1))\n",
    "\n",
    "            u = psi_and_p[:,0:1]\n",
    "            v = psi_and_p[:,1:2]\n",
    "            p = psi_and_p[:,2:3]\n",
    "\n",
    "\n",
    "            u_t = tape.gradient(u,t)\n",
    "            v_t = tape.gradient(v,t)\n",
    "\n",
    "            u_x = tape.gradient(u,x)\n",
    "            u_xx = tape.gradient(u_x,x)\n",
    "\n",
    "            u_y = tape.gradient(u,y)\n",
    "            u_yy = tape.gradient(u_y,y)\n",
    "\n",
    "            v_x = tape.gradient(v,x)\n",
    "            v_xx = tape.gradient(v_x,x)\n",
    "\n",
    "            v_y = tape.gradient(v,y)\n",
    "            v_yy = tape.gradient(v_y,y)\n",
    "\n",
    "            p_x = tape.gradient(p,x)\n",
    "            p_y = tape.gradient(p,y)\n",
    "\n",
    "        del tape\n",
    "        \n",
    "        l1 = self.lambda1\n",
    "        l2 = self.lambda2\n",
    "        f_u, f_v = residual(u,v,u_t,v_t,u_x,u_xx,u_y,u_yy,v_x,v_xx,v_y,v_yy,p_x,p_y,l1, l2)\n",
    "\n",
    "        return f_u, f_v\n",
    "    \n",
    "    def loss_gradient(self,X,X0,u0, v0):\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            tape.watch(self.model.trainable_variables)\n",
    "            loss = self.loss(self, X, X0, u0, v0)\n",
    "            g = tape.gradient(loss, self.model.trainable_variables)\n",
    "\n",
    "        del tape\n",
    "        return loss, g\n",
    "\n",
    "    def optimization(self, cor=50, tol=1.0  * np.finfo(float).eps,  iter=50000, fun=50000, ls=50):\n",
    "        def time_step():\n",
    "            loss = self.loss(self, self.X, self.X0, self.u0, self.v0)\n",
    "            return loss\n",
    "        variables = self.model.trainable_variables\n",
    "\n",
    "        dde.optimizers.config.set_LBFGS_options(maxcor=cor, ftol=tol,  maxiter=iter, maxfun=fun, maxls=ls)\n",
    "        dde.optimizers.tfp_optimizer.lbfgs_minimize(variables, time_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [3, 20, 20, 20, 20, 20, 20, 20, 20, 3]\n",
    "    \n",
    "    # Load Data\n",
    "data = scipy.io.loadmat('../Data/cylinder_nektar_wake.mat')\n",
    "\n",
    "U_star = data['U_star'] # N x 2 x T\n",
    "P_star = data['p_star'] # N x T\n",
    "t_star = data['t'] # T x 1\n",
    "X_star = data['X_star'] # N x 2\n",
    "\n",
    "N = X_star.shape[0]\n",
    "T = t_star.shape[0]\n",
    "\n",
    "# Rearrange Data \n",
    "XX = np.tile(X_star[:,0:1], (1,T)) # N x T\n",
    "YY = np.tile(X_star[:,1:2], (1,T)) # N x T\n",
    "TT = np.tile(t_star, (1,N)).T # N x T\n",
    "\n",
    "UU = U_star[:,0,:] # N x T\n",
    "VV = U_star[:,1,:] # N x T\n",
    "PP = P_star # N x T\n",
    "\n",
    "x = XX.flatten()[:,None] # NT x 1\n",
    "y = YY.flatten()[:,None] # NT x 1\n",
    "t = TT.flatten()[:,None] # NT x 1\n",
    "\n",
    "u = UU.flatten()[:,None] # NT x 1\n",
    "v = VV.flatten()[:,None] # NT x 1\n",
    "p = PP.flatten()[:,None] # NT x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(N*T, 5000, replace=False)\n",
    "x_train = x[idx,:]\n",
    "y_train = y[idx,:]\n",
    "t_train = t[idx,:]\n",
    "u_train = u[idx,:]\n",
    "v_train = v[idx,:]\n",
    "\n",
    "# Training\n",
    "model = PhysicsInformedNN(lb, ub, layers, u0, v0, x0, X):\n",
    "model.train(200000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
